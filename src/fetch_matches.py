import requests
import json
import os
import time
import random
import logging
from datetime import date, timedelta
from src import config
from upstash_redis import Redis

# ============================================
# CONFIGURA√á√ïES GERAIS
# ============================================
API_KEY = os.getenv("API_FOOTBALL_KEY")
BASE_URL = os.getenv("API_FOOTBALL_BASE", "https://v3.football.api-sports.io/")
SEASON = os.getenv("API_FOOTBALL_SEASON", "2024")
SCRAPING_API_KEY = os.getenv("WEBSCRAPING_API_KEY")

PRED_PATH = "data/predict/predictions.json"
HEADERS = {"x-apisports-key": API_KEY}
logger = logging.getLogger("football_api")

redis = config.redis_client  # Redis partilhado do projeto


# ============================================
# CACHE REDIS
# ============================================
def redis_cache_get(key):
    try:
        if redis:
            cached = redis.get(key)
            if cached:
                return json.loads(cached)
    except Exception:
        pass
    return None


def redis_cache_set(key, data, expire=3600):
    try:
        if redis:
            redis.set(key, json.dumps(data), ex=expire)
    except Exception:
        pass


# ============================================
# REQUEST SEGURO COM CACHE
# ============================================
def safe_request(url, params=None):
    key = f"cache:{url}:{json.dumps(params, sort_keys=True)}"
    cached = redis_cache_get(key)
    if cached:
        return cached

    try:
        r = requests.get(url, headers=HEADERS, params=params, timeout=5)
        if r.status_code == 200:
            data = r.json().get("response", [])
            redis_cache_set(key, data)
            return data
        else:
            logger.warning(f"‚ö†Ô∏è Erro {r.status_code} em {url}")
            return []
    except Exception as e:
        logger.error(f"‚ùå Timeout/API error em {url}: {e}")
        return []


# ============================================
# FALLBACK ‚Äî WEBSCRAPING.AI
# ============================================
def scrape_fixtures_with_webscrapingai(league_id):
    """Usa WebScraping.AI como fallback quando a API-Football n√£o retorna jogos."""
    if not SCRAPING_API_KEY:
        logger.warning("‚ö†Ô∏è WEBSCRAPING_API_KEY n√£o definida, fallback inativo.")
        return []

    try:
        scraping_url = "https://api.webscraping.ai/html"
        target_url = f"https://www.sofascore.com/tournament/{league_id}/fixtures"

        logger.info(f"üï∑Ô∏è Scraping de {target_url}")

        resp = requests.get(
            scraping_url,
            params={"api_key": SCRAPING_API_KEY, "url": target_url},
            timeout=20,
        )

        if resp.status_code == 200 and "html" in resp.text:
            # Aqui poderias integrar BeautifulSoup, mas no Render o parsing deve ser leve.
            logger.info("‚úÖ Conte√∫do HTML recebido via WebScraping.AI")
            return [{"league_id": league_id, "scraped": True, "source": "webscraping.ai"}]
        else:
            logger.warning(f"‚ö†Ô∏è Scraping falhou ({resp.status_code})")
            return []
    except Exception as e:
        logger.error(f"‚ùå Erro no fallback WebScraping.AI: {e}")
        return []


# ============================================
# PREDI√á√ÉO DE RESULTADOS
# ============================================
def calculate_prediction(stats_home, stats_away):
    try:
        avg_goals_home = float(stats_home.get("goals", {}).get("for", {}).get("average", {}).get("home", 1.2))
        avg_goals_away = float(stats_away.get("goals", {}).get("for", {}).get("average", {}).get("away", 1.1))
        avg_concede_home = float(stats_home.get("goals", {}).get("against", {}).get("average", {}).get("home", 1.0))
        avg_concede_away = float(stats_away.get("goals", {}).get("against", {}).get("average", {}).get("away", 1.0))

        home_score = (avg_goals_home + avg_concede_away) / 2
        away_score = (avg_goals_away + avg_concede_home) / 2

        predicted_home = max(0, round(home_score + random.uniform(-0.4, 0.4)))
        predicted_away = max(0, round(away_score + random.uniform(-0.4, 0.4)))

        confidence = round(0.55 + abs(predicted_home - predicted_away) * 0.1 + random.uniform(0.05, 0.15), 2)
        confidence = min(confidence, 0.95)

        return {
            "predicted_score": {"home": predicted_home, "away": predicted_away},
            "confidence": confidence,
        }
    except Exception:
        return {
            "predicted_score": {"home": random.randint(0, 3), "away": random.randint(0, 3)},
            "confidence": round(random.uniform(0.5, 0.7), 2),
        }


# ============================================
# FUN√á√ÉO PRINCIPAL ‚Äî JOGOS E PREVIS√ïES
# ============================================
def fetch_today_matches():
    if not API_KEY:
        print("‚ùå API_FOOTBALL_KEY n√£o definida.")
        return {"status": "error", "detail": "API key missing"}

    LEAGUE_IDS = [39, 140, 135, 78, 61, 94, 88, 2]
    matches = []
    total = 0

    print(f"üî¢ Total de ligas configuradas: {len(LEAGUE_IDS)} | Season: {SEASON}")

    for day_offset in range(3):
        match_date = (date.today() + timedelta(days=day_offset)).strftime("%Y-%m-%d")
        print(f"\nüìÖ Buscando jogos de {match_date}...")

        for league_id in LEAGUE_IDS:
            fixtures_url = f"{BASE_URL}fixtures"
            data = safe_request(fixtures_url, {"league": league_id, "season": SEASON, "date": match_date})

            if not data:
                # fallback WebScraping.AI
                scraped = scrape_fixtures_with_webscrapingai(league_id)
                if scraped:
                    logger.info(f"üï∑Ô∏è Jogos obtidos via fallback ({league_id})")
                    continue
                else:
                    continue

            for f in data:
                fixture = f.get("fixture", {})
                league = f.get("league", {})
                teams = f.get("teams", {})

                pred = calculate_prediction({}, {})
                match = {
                    "match_id": fixture.get("id"),
                    "league": league.get("name"),
                    "league_id": league_id,
                    "home_team": teams.get("home", {}).get("name"),
                    "away_team": teams.get("away", {}).get("name"),
                    "date": fixture.get("date"),
                    "predicted_score": pred["predicted_score"],
                    "confidence": pred["confidence"],
                }
                matches.append(match)
                total += 1

                print(f"‚öΩ {match['home_team']} vs {match['away_team']} ‚Üí "
                      f"{pred['predicted_score']['home']}-{pred['predicted_score']['away']} "
                      f"(confian√ßa {pred['confidence']*100:.0f}%)")

    os.makedirs(os.path.dirname(PRED_PATH), exist_ok=True)
    with open(PRED_PATH, "w", encoding="utf-8") as f:
        json.dump(matches, f, ensure_ascii=False, indent=2)

    print(f"\n‚úÖ {total} previs√µes salvas em {PRED_PATH}")
    return {"status": "ok", "total": total}


if __name__ == "__main__":
    result = fetch_today_matches()
    print(result)
